{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEEJIYOUNG245/covid19/blob/main/vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS4UhS-P0tU5",
        "outputId": "3779ab4d-d95f-45b2-c30f-d0411512719f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI8oPA0e2Xle"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import time, copy\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA2e-edR4GJP"
      },
      "source": [
        "# **파일Path 작업**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjQRG8bliqlj"
      },
      "source": [
        "PATH = \"/content/gdrive/MyDrive/개인/CT_DATA_SPLITTED\"\n",
        "Folder = os.listdir(PATH)\n",
        "\n",
        "train_path = []\n",
        "val_path = []\n",
        "test_path = []\n",
        "li =[train_path, val_path, test_path]\n",
        "\n",
        "for index, folder in enumerate(Folder):\n",
        "  folder_path = os.path.join(PATH,folder)\n",
        "  file_path = os.listdir(folder_path)\n",
        "  file_list = []\n",
        "  for filename in file_path:\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    file_list.append(file_path)\n",
        "  li[index] += file_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVkOhT-LjzxO",
        "outputId": "71a50c1f-083f-4c51-f207-815065e4067d"
      },
      "source": [
        "print(len(train_path),len(val_path),len(test_path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "447 148 148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnbDD2IJj4Gd"
      },
      "source": [
        "# **label별 분포도 출력**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "qmNSgZx5j6qW",
        "outputId": "34a6c22e-9b83-499d-80f9-8c7396e86a15"
      },
      "source": [
        "#label별 count\n",
        "class compare_covid_dataset():\n",
        "    def __init__(self,li):\n",
        "        self.li = li\n",
        "        self.cnt_li = [[0,0],[0,0],[0,0]]\n",
        "\n",
        "        for index, folder in enumerate(li):\n",
        "            for i in folder:\n",
        "                if 'CT_COVID' in i:\n",
        "                    self.cnt_li[index][0]+=1\n",
        "                else:\n",
        "                    self.cnt_li[index][1]+=1\n",
        "\n",
        "        self.train_cat_cnt = self.cnt_li[0][0]            \n",
        "        self.train_dog_cnt = self.cnt_li[0][1]\n",
        "        self.valid_cat_cnt = self.cnt_li[1][0]\n",
        "        self.valid_dog_cnt = self.cnt_li[1][1]\n",
        "        self.test_cat_cnt = self.cnt_li[2][0]\n",
        "        self.test_dog_cnt = self.cnt_li[2][1]\n",
        "    def __call__(self):\n",
        "        #draw plt\n",
        "        label = ['train', 'valid','test']\n",
        "        cat = [self.train_cat_cnt,self.valid_cat_cnt,self.test_cat_cnt]\n",
        "        dog = [self.train_dog_cnt,self.valid_dog_cnt,self.test_dog_cnt]\n",
        "        plt.rcParams[\"font.size\"] = 12\n",
        "        plt.figure(figsize=(12,8))\n",
        "\n",
        "        x = np.arange(len(label))\n",
        "\n",
        "        plt.bar(x-0.15, cat, label='CT_COVID', width=0.3, color='#FF0000')\n",
        "        plt.bar(x+0.15, dog, label='CT_NonCOVID', width=0.3, color='#FFFF00')\n",
        "        plt.legend()\n",
        "        plt.xticks(x, label)\n",
        "        plt.ylabel('Number of data')\n",
        "        plt.title('Compare DATASETS')\n",
        "        plt.show()\n",
        "\n",
        "show =compare_covid_dataset(li)\n",
        "show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzF7n6nUGXPA"
      },
      "source": [
        "# **Aug Compose**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwswzgZkGDOw"
      },
      "source": [
        "train_transform = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_transform = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqTnQ7lPGes5"
      },
      "source": [
        "# **DataSet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmVnqIw3iAST"
      },
      "source": [
        "class cd_Dataset(Dataset):\n",
        "    def __init__(self ,transform =None, FILE_PATHS= None):\n",
        "        self.transform = transform\n",
        "        self.FILE_PATHS = FILE_PATHS\n",
        "        self.Image_List=[]\n",
        "        self.Label_List=[]\n",
        "\n",
        "        #라벨링\n",
        "        for i in range(len(FILE_PATHS)):\n",
        "            if 'CT_NonCOVID' in FILE_PATHS[i]:\n",
        "                self.Image_List.append(FILE_PATHS[i])\n",
        "                self.Label_List.append(1)\n",
        "            elif 'CT_COVID' in FILE_PATHS[i]:\n",
        "                self.Image_List.append(FILE_PATHS[i])\n",
        "                self.Label_List.append(0)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.Label_List)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.Label_List[idx]\n",
        "        img = Image.open(self.Image_List[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grmEFHWviB2q"
      },
      "source": [
        "Train = cd_Dataset(transform=train_transform, FILE_PATHS= train_path)\n",
        "Val = cd_Dataset(transform=test_transform, FILE_PATHS= val_path)\n",
        "Test = cd_Dataset(transform=test_transform, FILE_PATHS = test_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SATWy3ciFtT"
      },
      "source": [
        "train_data_loader = DataLoader(Train, batch_size = 16, shuffle=True, num_workers=2)\n",
        "test_data_loader = DataLoader(Val, batch_size = 16, shuffle=False, num_workers=2)\n",
        "real_test_data_loader = DataLoader(Test, batch_size = 16, shuffle = False, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLuBR5crO3xu"
      },
      "source": [
        "# **Model 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MpaalSlOzVA"
      },
      "source": [
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yss3Gxl-O6hE",
        "outputId": "b14b8d65-aa6b-419f-d166-b63b4d25c51b"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG,self).__init__()\n",
        "        self.vgg_name = vgg_name\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.classifier(out)\n",
        "        return F.sigmoid(out)\n",
        "    \n",
        "    def _make_layers(self, cfg):\n",
        "        layers=  []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else :\n",
        "                layers += [nn.Conv2d(in_channels=in_channels, out_channels=x ,kernel_size=(3,3),stride =1, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)  # inplace 메모리 감소\n",
        "                           ]\n",
        "                in_channels = x\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = VGG('VGG16')\n",
        "    x = torch.randn(16,3,224,224)\n",
        "    y = net(x)\n",
        "    print(y.size())\n",
        "test()\n",
        "model = VGG('VGG16')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpi_7qxAPB6M"
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k_peEjyPF6R"
      },
      "source": [
        "# **Train & Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ3k0O-4PDzk"
      },
      "source": [
        "class TrainModel():\n",
        "    def __init__(self,model, criterion, optimizer, trainloader, testloader, num_epochs=5):\n",
        "        \n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        self.model = model.to(self.device)\n",
        "        self.trainloader =trainloader\n",
        "        self.testloader = testloader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.num_epochs = num_epochs\n",
        "        self.best_acc_wts = copy.deepcopy(self.model.state_dict())\n",
        "        self.best_acc =0.0\n",
        "\n",
        "        \n",
        "        for epoch in range(1, self.num_epochs+1):\n",
        "            print('Epoch {}/{}'.format(epoch, self.num_epochs))\n",
        "            self.train()\n",
        "            self.test()\n",
        "\n",
        "        model.load_state_dict(self.best_acc_wts)\n",
        "    def train(self):\n",
        "        self.model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(self.trainloader):\n",
        "            inputs = inputs.to(self.device)\n",
        "            targets = targets.unsqueeze(1).to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.criterion(outputs, targets.float())\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            for i in range(0,len(outputs)):\n",
        "                if outputs[i][0].data.cpu().numpy()> 0.5:\n",
        "                    outputs[i][0] =1\n",
        "                else:\n",
        "                    outputs[i][0] =0            \n",
        "\n",
        "            train_loss += loss.data.cpu().numpy()\n",
        "            total += targets.size(0)\n",
        "            correct += outputs.eq(targets).sum().item()\n",
        "\n",
        "        epoch_loss = train_loss /len(self.trainloader)\n",
        "        epoch_acc = correct / total\n",
        "        print('train | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n",
        "\n",
        "    def test(self):\n",
        "        self.model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(self.testloader):\n",
        "                inputs = inputs.to(self.device)\n",
        "                targets = targets.unsqueeze(1).to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, targets.float())\n",
        "\n",
        "                for i in range(0,len(outputs)):\n",
        "                    if outputs[i][0].data.cpu().numpy()> 0.5:\n",
        "                        outputs[i][0] =1\n",
        "                    else:\n",
        "                        outputs[i][0] =0            \n",
        "\n",
        "                test_loss += loss.data.cpu().numpy()\n",
        "                total += targets.size(0)\n",
        "                correct += outputs.eq(targets).sum().item()\n",
        "\n",
        "            epoch_loss = test_loss /len(self.testloader)\n",
        "            epoch_acc = correct / total\n",
        "            print('test | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n",
        "            if epoch_acc >= self.best_acc:\n",
        "                self.best_acc = epoch_acc\n",
        "                self.best_acc_wts = copy.deepcopy(self.model.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU2BKOuWPM06",
        "outputId": "25e0c738-b690-4072-8a0b-98de137234f7"
      },
      "source": [
        "TrainModel(model, criterion=criterion, optimizer=optimizer,trainloader=train_data_loader,testloader=test_data_loader,num_epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train | Loss: 0.6953 Acc: 0.4899\n",
            "test | Loss: 0.6889 Acc: 0.5338\n",
            "Epoch 2/10\n",
            "train | Loss: 0.6855 Acc: 0.5213\n",
            "test | Loss: 0.6845 Acc: 0.5338\n",
            "Epoch 3/10\n",
            "train | Loss: 0.6702 Acc: 0.5615\n",
            "test | Loss: 0.6891 Acc: 0.5743\n",
            "Epoch 4/10\n",
            "train | Loss: 0.6430 Acc: 0.6532\n",
            "test | Loss: 0.6713 Acc: 0.6014\n",
            "Epoch 5/10\n",
            "train | Loss: 0.5802 Acc: 0.7136\n",
            "test | Loss: 0.6228 Acc: 0.6419\n",
            "Epoch 6/10\n",
            "train | Loss: 0.5334 Acc: 0.7315\n",
            "test | Loss: 0.9163 Acc: 0.6689\n",
            "Epoch 7/10\n",
            "train | Loss: 0.5213 Acc: 0.7606\n",
            "test | Loss: 0.7059 Acc: 0.6554\n",
            "Epoch 8/10\n",
            "train | Loss: 0.4543 Acc: 0.7942\n",
            "test | Loss: 0.6983 Acc: 0.6419\n",
            "Epoch 9/10\n",
            "train | Loss: 0.4215 Acc: 0.8031\n",
            "test | Loss: 0.5692 Acc: 0.6959\n",
            "Epoch 10/10\n",
            "train | Loss: 0.4213 Acc: 0.8300\n",
            "test | Loss: 0.6288 Acc: 0.7230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TrainModel at 0x7f5c04a9ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHuiSyBIamD9"
      },
      "source": [
        "def test(model,testloader,criterion):\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.unsqueeze(1).to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets.float())\n",
        "\n",
        "                for i in range(0,len(outputs)):\n",
        "                    if outputs[i][0].data.cpu().numpy()> 0.5:\n",
        "                        outputs[i][0] =1\n",
        "                    else:\n",
        "                        outputs[i][0] =0            \n",
        "\n",
        "                test_loss += loss.data.cpu().numpy()\n",
        "                total += targets.size(0)\n",
        "                correct += outputs.eq(targets).sum().item()\n",
        "                \n",
        "            epoch_loss = test_loss /len(testloader)\n",
        "            epoch_acc = correct / total\n",
        "            print('test | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n",
        "\n",
        "class FeatureExtractor_vgg():\n",
        "    \"\"\" Class for extracting activations and\n",
        "    registering gradients from targetted intermediate layers \"\"\"\n",
        "\n",
        "    def __init__(self, model, target_layers): # target_layers = 35 ==> VGG19에서 가장 마지막 MaxPool2D전 ReLU함수\n",
        "        self.model = model\n",
        "        self.target_layers = target_layers\n",
        "        self.gradients = []\n",
        "\n",
        "    def save_gradient(self, grad):\n",
        "        self.gradients.append(grad)\n",
        "\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.gradients = []\n",
        "        for name, module in self.model._modules.items(): # 모든 layer에 대해서 직접 접근\n",
        "            x = module(x)\n",
        "            if name in self.target_layers: # target_layer라면 해당 layer에서의 gradient를 저장\n",
        "                x.register_hook(self.save_gradient) #\n",
        "                target_feature_maps = x # x's shape = 512X14X14(C,W,H) feature map\n",
        "        return target_feature_maps, x\n",
        "\n",
        "\n",
        "class ModelOutputs_vgg():\n",
        "    \"\"\" Class for making a forward pass, and getting:\n",
        "    1. The network output.\n",
        "    2. Activations from intermeddiate targetted layers.\n",
        "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
        "\n",
        "    def __init__(self, model, target_layers):\n",
        "        self.model = model\n",
        "        self.feature_extractor = FeatureExtractor_vgg(self.model.features, target_layers)\n",
        "\n",
        "    def get_gradients(self):\n",
        "        return self.feature_extractor.gradients\n",
        "\n",
        "    def __call__(self, x):\n",
        "        target_activations, output = self.feature_extractor(x)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.model.classifier(output) # feature extract를 통해서 나온 값을 활용하여 classification 진행\n",
        "        #print(\"ModelOutputs().output.shape : \",output[0])\n",
        "        #print(\"ModelOutputs().target_activations.shape :\",target_activations[0])\n",
        "        return target_activations, output\n",
        "\n",
        "class GradCam_vgg:\n",
        "    def __init__(self, model, target_layer_names, use_cuda):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.cuda = use_cuda\n",
        "        if self.cuda: # GPU일 경우 model을 cuda로 설정\n",
        "            self.model = model.cuda()\n",
        "\n",
        "        self.extractor = ModelOutputs_vgg(self.model, target_layer_names)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "    def __call__(self, input, index=None):\n",
        "        if self.cuda: # GPU일 경우 input을 cuda로 변환하여 전달\n",
        "            features, output = self.extractor(input.cuda())\n",
        "        else:\n",
        "            features, output = self.extractor(input)\n",
        "        #print(\"features : \",features.cpu().data.numpy().shape) # 해당 위치에서 추출된 feature map ( 512,14,14 ) (ChannelX14X14)\n",
        "        #print(\"output : \",output.cpu().data.numpy().shape) # class를 의미함\n",
        "        probs, idx = 0,0\n",
        "        #print(\"index : \", index)\n",
        "        if index == None:\n",
        "            index = np.argmax(output.cpu().data.numpy())  # index = 정답이라고 추측한 class index\n",
        "            h_x = F.softmax(output,dim=1).data.squeeze()\n",
        "            probs, idx = h_x.sort(0,True)\n",
        "        #print(\"index : \", index)\n",
        "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
        "        one_hot[0][index] = 1 # 정답이라고 생각하는 class의 index 리스트 위치의 값만 1로\n",
        "        one_hot = torch.from_numpy(one_hot).requires_grad_(True) # numpy배열을 tensor로 변환\n",
        "        # requires_grad == True 텐서의 모든 연산에 대하여 추적\n",
        "        if self.cuda:\n",
        "            one_hot = torch.sum(one_hot.cuda() * output)\n",
        "        else:\n",
        "            one_hot = torch.sum(one_hot * output)\n",
        "\n",
        "        self.model.features.zero_grad()\n",
        "        self.model.classifier.zero_grad()\n",
        "        one_hot.backward(retain_graph=True)\n",
        "\n",
        "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
        "        #print(\"grads_val : \",grads_val.shape) # 512 X 14 X 14\n",
        "        target = features  # A^k\n",
        "        target = target.cpu().data.numpy()[0, :]\n",
        "\n",
        "        cam = None\n",
        "\n",
        "        weights = np.mean(grads_val, axis=(2, 3))[0, :]  # 논문에서의 global average pooling 식에 해당하는 부분\n",
        "        grad_cam = np.zeros(target.shape[1:], dtype=np.float32)  # 14X14\n",
        "\n",
        "        for i, w in enumerate(weights):  # calcul grad_cam\n",
        "            grad_cam += w * target[i, :, :]  # linear combination L^c_{Grad-CAM}에 해당하는 식에서 ReLU를 제외한 식\n",
        "\n",
        "        grad_cam = np.maximum(grad_cam, 0)  # 0보다 작은 값을 제거\n",
        "        grad_cam = cv2.resize(grad_cam, (224, 224))  # 224X224크기로 변환\n",
        "        grad_cam = grad_cam - np.min(grad_cam)  #\n",
        "        grad_cam = grad_cam / np.max(grad_cam)  # 위의 것과 해당 줄의 것은 0~1사이의 값으로 정규화하기 위한 정리\n",
        "        return grad_cam, cam, index, probs, idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGmk2ID0angV",
        "outputId": "a49f6a35-79ae-43b7-c697-c7fe4bfc72e9"
      },
      "source": [
        "test(model,test_data_loader,criterion)\n",
        "GradCam_vgg(model, target_layer_names = 8, use_cuda = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test | Loss: 0.6288 Acc: 0.7230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.GradCam_vgg at 0x7f5be25161d0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}